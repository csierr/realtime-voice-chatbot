# ğŸ—£ï¸ Realtime Voice Chatbot

This is a personal project to develop a local application using FastAPI that interacts with OpenAI's Realtime API. The app allows users to chat via text (already implemented) and voice (**under development**).

## âœ¨ Features

- Text chat with OpenAI's Realtime API
- Buffered audio playback that receives audio chunks via WebSocket and plays them after full reception
- WebSocket communication between frontend and backend
- FastAPI backend serving both HTML and WebSocket endpoints
- Environment variables managed via `.env` file (not pushed to github, but .env.example provided)

Claro, aquÃ­ tienes la estructura del proyecto correctamente formateada en Markdown:


## ğŸ“ Project Structure

```
realtime-voice-chatbot/
â”œâ”€â”€ .env.example
â”œâ”€â”€ chatbot-screenshot.png
â”œâ”€â”€ .gitignore
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ README.md
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ websocket_server.py
â”‚   â””â”€â”€ my_realtime_client.py
â””â”€â”€ public/
    â”œâ”€â”€ index.html
    â”œâ”€â”€ favicon-32x32.png
    â”œâ”€â”€ css/
    â”‚   â””â”€â”€ styles.css
    â””â”€â”€ js/
        â””â”€â”€ main.cjsss
```



## ğŸ§° Tech Stack

- **FastAPI** â€” Web framework for building APIs
- **Uvicorn** â€” ASGI server to run the FastAPI app
- **OpenAI API** â€” OpenAI Realtime API for real-time interaction
- **Python** â€” Main programming language
- **HTML** â€” Simple frontend for user interaction
- **WebSocket** â€” For real-time communication
- **PyAudio** â€” For handling audio input/output

## ğŸš€ Installation

1. Clone the repository:

   ```bash
   git clone https://github.com/csierr/realtime-voice-chatbot.git
   cd realtime-voice-chatbot

2. Create and activate a virtual environment:

    ```bash
    python -m venv .venv
    source .venv/Scripts/activate  # Windows
    source .venv/bin/activate      # Linux/Mac

3. Install dependencies:

    ```bash
    pip install -r requirements.txt

4. Create a `.env` file based on `.env.example`, and insert your OpenAI API key.


## âš¡ Usage

Access the app at http://localhost:8000  after running the backend locally:

```bash
uvicorn src.websocket_server:app --reload
```

When you access the app you need to **click anywhere on the page to enable audio playback**. This is due to restrictions in modern browsers, which block media playback automatically until the user interacts with the page. Once you click, the audio playback functionality should work as expected.

## ğŸš§ Project Status

This project is a work in progress:

âœ… Text conversation with OpenAI is functional

âœ… Audio reception & playback

ğŸ›  Audio input from browser **is under active development**

ğŸ“ More features and improvements planned

The current audio implementation buffers chunks and starts playback only after the final `audio_done` signal is received. True streaming playback is not yet supported.



# ğŸ–¼ï¸ Preview

Hereâ€™s a preview of the app in action!

In the screenshot, you can see the app running, with the terminal/console (opened via F12) visible to monitor logs and see what's happening behind the scenes in real time.

![Realtime_voice_chat](chatbot-screenshot.png)